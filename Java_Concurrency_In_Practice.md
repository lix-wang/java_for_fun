## Java Concurrency In Practice Notes

* [1.Introduction](#1)
* [2.对象的组合](#2)
* [3.中断](#3)
* [4.Executor](#4)
* [5.活跃性、性能与测试](#5)
* [6.性能与可伸缩性](#6)

<h2 id="1">1.Introduction</h2>
&emsp;&emsp; Java中主要同步机制是关键字synchromized，还包括volatile类型的变量，显式锁，原子变量。多个线程访问同一个可变的状态变量时，
没有使用合适的同步，那么程序会出错，三种方式可修复问题：1.不在线程之间共享状态变量。2.将状态变量修改为不可变的变量。3.在访问状态变量时使用同步。

<br>
&emsp;&emsp; 无状态的对象一定是线程安全的，例如：Servlet。实际中尽量使用线程安全对象来管理类的状态，如AtomicLong。
Java提供了一种内置的锁机制来支持原子性：同步代码块（Synchronized Block）。同步代码块分两部分：一个作为锁的对象的引用，一个作为由这个锁保护的代码块。
以关键字synchronized来修饰的方法是一种横跨整个方法体的同步代码块，其中该同步代码块的锁就是方法调用所在的对象，静态synchronized方法以Class对象作为锁。

    <p>
    synchronized (lock) {
        // ops
    }
    </p>

<br>
&emsp;&emsp; 每个Java对象都可以用做一个实现同步的锁，这些锁被称为内置锁(Intrinsic Lock)或监视锁(Monitor Lock)。
线程在进入同步代码块之前会自动获得锁，并且无论正常退出还是抛异常退出同步代码块时，都会自动释放锁。获得内置锁唯一的方式就是进入这个锁保护的同步代码块或方法。
Java的内置锁是互斥锁，意味着最多只有一个线程能持有这种锁。

<br>
&emsp;&emsp; 内置锁是可重入的，如果一个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。获取锁的操作的粒度是线程而不是调用。
重入的一种实现方法是为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有，当线程请求一个没有被持有的锁时，
JVM记录下锁的持有者并将计数器置1，如果同一个线程再次获取这个锁，那么计数值递增，当线程退出同步代码块时，计数器会相应的递减，当计数器值为0时，
这个锁将被释放。

<br>
&emsp;&emsp; 对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁，在这种情况下，我们称状态变量是由这个锁保护的。
对象的内置锁与其状态之间没有内在的关联，大多数类都将内置锁用做一种有效的加锁机制，但对象的域并不一定要通过内置锁保护，当获取与对象关联的锁时，
并不能阻止其他线程访问该对象，某个线程在获得对象的锁之后，只能阻止其他线程获得同一个锁。之所以每个对象都有一个内置锁，只是为了避免显式地创建锁对象。
每个共享可变的变量都应该只由一个锁来保护。

<br>
&emsp;&emsp; 一种常见的加锁约定是，将所有可变状态都封装在对象内部，通过对象内置锁对所有访问可变状态的代码路径进行同步，使得在该对象上不会发生并发访问。
例如：Vector和其他同步集合类。如果在添加新的方法或代码路径时忘了使用同步，那么这种加锁协议很容易就被破坏。

<br>
&emsp;&emsp; 对于每个包含多个变量的不变性条件，其中涉及的所有变量都需要由同一个锁来保护。当执行时间较长的计算或者可能无法快速完成的操作时，
一定不要持有锁。当线程在没有同步的情况下读取变量时，可能得到一个失效值，这个值是由之前某个线程设置的值，而不是随机值，这种安全性保证被称为最低安全性。
最低安全性使用于绝大多数变量，但存在一个例外，非volatile类型的64位数值变量(double 和 long)。Java内存模型要求，变量的读和写操作都必须是原子操作。
但对于非volatile类型的long和double，JVM允许将64位的读或写操作，分解为两个32位的操作。在多线程中使用共享且可变的long和double，是不安全的，
除非用volatile声明或用锁保护起来。

<br>
&emsp;&emsp; 访问某个共享且可变的变量时要求所有线程在同一个锁上同步，用来保证某个线程写入该变量的值对于其他线程来说是可见的。

<br>
&emsp;&emsp; 当变量声明为volatile时，编译器与运行时不会将该变量上的操作与其他内存操作重排序。volatile变量不会被缓存在寄存器或其他处理器不可见的地方，
因此在读取colatile变量时总会返回最新写入的值。volatile变量是一种比synchronize关键字更轻量级的同步机制。不建议过度依赖volatile变量提供可见性，
在代码中过度依赖volatile控制状态的可见性，通常比锁更脆弱，也更难理解。volatile正确的使用方式包括：确保它们自身状态的可见性，
确保它们所引用对象的状态的可见性，以及标识一些重要的程序生命周期时间的发生。

<br>
&emsp;&emsp; 当且仅当满足以下条件时，才使用colatile变量：对变量的写入操作不依赖变量的当前值，或者能确保只有单个线程更新变量的值。
该变量不会与其他状态变量一起纳入不变性条件中。在访问变量时不需要加锁。

<br>
&emsp;&emsp; 发布(Publish) 一个对象，是指对象能够在当前作用域之外的代码中使用。发布对象最简单的方法是将对象的引用保存到一个公有的静态变量中，
以便任何类和线程都能看见该对象。

<br>
&emsp;&emsp; ThreadLocal能使线程中的某个值与保存值的对象关联起来。ThreadLocal提供了get set方法，这些方法为每个使用该变量的线程都留有一份独立的副本。
因此get总是返回由当前执行线程在调用set时设置的最新值。ThreadLocal 对象通常用于防止对可变的单实例变量或全局变量进行共享。
ThreadLocal用来维持线程封闭性。ThreadLocal变量类似于全局变量，能降低代码的可重用性，并在类之间引入隐含的耦合性，因此使用时要格外小心。

<br>
&emsp;&emsp; 不可变对象一定是线程安全的。不可变性不等于将对象的所有域声明为final，即使对象中所有域都是final类型的，对象仍然是可变的，
因为在final域中可以保存对可变对象的引用。满足以下条件时，对象才是不可变的：对象创建后状态不能修改，对象所有的域都是final，对象是正确创建的，
在对象创建期间，this引用没有逸出。如果final类型的域指向的是可变对象，那么在访问这些域所指向的对象的状态时，仍然需要使用同步。

<br>
&emsp;&emsp; 要安全的发布一个正确构造的对象，可以通过以下方式：在静态初始化函数中初始化一个对象引用；将对象的引用保存到volatile类型的域或AtomicReferance对象中；
将对象的引用保存到某个正确构造对象的final类型域中；将对象的引用保存到一个由锁保护的域中。

<br>
&emsp;&emsp; 线程安全库中的容器类提供了以下安全发布保证：1.通过将一个键或值放入HashTable、SynchronizedMap、或ConcurrentMap中，
可以安全的将它发布给任何从这些容器中访问它的线程。2.通过将某个元素放入Vector、CopyOnWriteArrayList、CopyOnWriteArraySet、SynchronizedList
或SynchronizedSet中，可以将该元素安全的发布到任何从这些容器中访问该元素的线程。3.通过将某个元素放入BlockingQueue或ConcurrentLinkedQueue中，
可以将该元素安全的发布到任何从这些队列中访问元素的线程。

<br>
&emsp;&emsp; 类库中其他数据传递机制（Future 和 Exchanger）同样能实现安全发布。通常发布一个静态构造的对象，最简单安全的方式是使用静态的初始化器，
静态初始化器由JVM在类的初始化阶段执行，由于JVM内部存在同步机制，因此通过这种方式初始化的任何对象都能被安全的发布。

    <p>
    public static Holder holder = new Holder(123);
    </p>
    
<br>
&emsp;&emsp; 如果对象从技术上来看是可变的，但其状态在发布后不会再改变，那么把这种对象称为事实不可变对象。
对象的发布需求取决于它的可变性：1.不可变对象可以通过任意机制来发布。2.事实不可变对象必须通过安全方式发布。3.可变对象必须通过安全方式发布，
并且必须是线程安全的或者由某个锁保护起来。

<br>
&emsp;&emsp; 在并发程序中使用和共享对象时，可以采用一些策略：1.线程封闭，线程封闭的类只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改。
2.只读共享，在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程不能修改它，共享的只读对象包括不可变对象和事实不可变对象。
3.线程安全共享，线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。
4.保护对象，被保护的对象只能通过持有特定的锁来访问，保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定的锁保护的对象。

<h2 id="2">2.对象的组合</h2>
&emsp;&emsp; 为了防止多个线程在并发访问同一个对象时产生的相互干扰，这些对象应该要么是线程安全的对象，要么是事实不可变的对象，或者由锁来保护的对象。
将数据封装在对象内部，可以将数据的访问限制在对象的方法上，从而更容易确保线程在访问数据时，总能持有正确的值。线程封闭通过确保对象只能由单个线程访问来实现。

<br>
&emsp;&emsp; 一些基本的容器类并不是线程安全的，如ArryList和HashMap，但通过包装器工厂方法，使得这些非线程安全的类可以在多线程的情况下使用，
这些工厂方法通过装饰器模式，将容器封装在一个同步的包装器对象中，包装器能将接口中的每个方法都实现为同步方法，并将调用请求转发到底层的容器对象上。
只要包装器对象拥有对底层容器对象的唯一引用，那么就是线程安全的。如：Collections.synchronizedList。

<br>
&emsp;&emsp; 遵循Java监视器模式的对象，会把对象的所有可变状态都封装起来，并由对象自己的内置锁保护。

<br>
&emsp;&emsp; 闭锁是一种同步工具，可以延迟线程的进度直到其到达终止状态。CountDownLatch是一种灵活的闭锁实现。可以使一个或多个线程等待一组事件的发生。
FutureTask 也可以用做闭锁，表示一种抽象的可生成结果的计算。FutureTask表示的计算是通过Callable实现的，相当于一种可生成结果的Runnable，
并且可处于以下三种状态：1.等待运行。2.正在运行。3.运行完成。执行完成表示计算的所有可能结束方式，包括正常结束、由于取消而结束和由于异常而结束。
当FutureTask进入结束状态后，会永远停止在这个状态。

<br>
&emsp;&emsp; 可以使用Semaphore将任何一种容器变成有界阻塞容器，信号量的计数值会初始化为容器容量的最大值。栅栏类似闭锁，能阻塞一组线程直到某个事件发生，
栅栏与闭锁的关键区别在于，所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，栅栏用于等待其他线程。

<br>
&emsp;&emsp; CyclicBarrier可以使一定数量的参与方反复地在栅栏位置汇集。在并行迭代算法中非常有用，通常将一个问题拆分成一系列相互独立的自问题。
当线程到达栅栏位置时将调用await方法，阻塞直到所有线程都到达栅栏的位置，如果所有线程到达了栅栏位置，栅栏将打开，所有线程被释放，栅栏被重置以便下次使用。
如果await调用超时，或者await阻塞被中断，那么栅栏被认为是打破了，所有阻塞的await调用都将终止，并抛出BrokenBarrierException。

<br>
&emsp;&emsp; 另一种形式的栅栏是Exchanger，是一种两方栅栏。

<h2 id="3">3.中断</h2>
&emsp;&emsp; 不要把不可靠的的取消操作至于阻塞操作中。否则可能会由于阻塞导致无法中断。如下程序，如果队列中元素已经满了，
那么在put时会一直阻塞，这时候，我们会发现，调用cancel()函数，并不会起任何作用。这时候，我们需要使用线程中断机制。

    <p>
        public class PrimeGenerator extends Thread {
            private final BlockingQueue<BigInteger> queue;
            private volatile boolean cancelled = false;
            
            public PrimeGenerator(BlockingQueue<BigInteger> queue) {
                this.queue = queue;
            }
            
            public void run() {
                try {
                    BigInteger p = BigInteger.ONE;
                    while(!cancelled) {
                        queue.put(p = p.nextProbablePrime());
                    }
                } catch(InterruptedException consumed) {
                    // do nothing;
                }
            }
            
            public void cancel() {
                this.cancelled = true;
            }
        }
        
        void consumePrime() {
            BlockingQueue<BigInteger> queue = new LinkedBlockingDeque<>();
            PrimeGenerator generator = new PrimeGenerator(queue);
            generator.start();
            try {
                while(needConsumeFlag) {
                    consume(queue.take());
                }
            } finally {
                generator.cancel();
            }
        }
    </p>
    
<br>
&emsp;&emsp; 线程分为两种：普通线程和守护线程。JVM启动时创建的所有线程中，除了主线程，其他的都是守护线程，当创建一个新的线程时，
新线程将继承创建它的线程的守护状态。因此主线程创建的线程都是普通线程。普通线程与守护线程的区别在于：当线程退出时，JVM会检查其他正在运行的线程，
如果这些线程都是守护线程，那么JVM会正常退出操作，当JVM停止时，所有仍然存在的守护线程都会被抛弃，既不会执行finally代码块，也不会执行回卷栈，
而JVM只是直接退出。所以尽可能少的试用守护线程，很少有操作能在不进行清理的情况下被安全的抛弃，当守护线程中包含IO操作任务，那么将是一种危险的行为，
守护线程最好用于执行内部任务，例如周期性的从内存的缓存中移除逾期的数据。

<br>
&emsp;&emsp; 当不需要内存资源时，可以通过垃圾回收器来回收，对于其他的资源如文件句柄或者套接字句柄，不需要时必须显式的交还给操作系统。
为了实现这个功能，垃圾回收器对那些定义了finalize方法的对象会进行特殊处理，在回收器释放它们后，调用它们的finalize方法，从而保证持久的资源被释放。
在大多数情况下，通过使用finally代码块和close方法，能够比使用终结器更好的管理资源。唯一的例外在于，当需要管理对象，并且该对象持有的资源，
是通过本地方法获得的。尽量避免编写或使用包含终结器的类，除非是平台库中的类。

<h2 id="4">4.Executor</h2>
&emsp;&emsp; 在单线程的Executor中，如果一个任务将另一个任务提交到同一个Executor，并且等待这个被提交任务的结果，那么将会引发死锁。
在更大的线程池中，如果所有正在执行任务的线程都由于等待其他仍处于工作队列中的任务而阻塞，那么会发生同样的问题，这个现象称为线程饥饿死锁。

<br>
&emsp;&emsp; 对于计算密集型的任务，在拥有N个处理器的系统上，当线程池大小为N + 1 时，通常能实现最优的利用率。
对于包含I／O操作或者其他阻塞操作的任务，由于线程并不会一直执行，因此线程池的规模应该更大。要正确设置线程池的大小，必须估算出任务的等待

<br>
&emsp;&emsp; N<sub>cpu</sub> = number of cpus;  U = target cpu utilization, 0 <= U <= 1; W/C = ratio of wait time to compute time;
要使处理器达到期望的使用率，线程池最优大小等于 N<sub>threads</sub> = N<sub>cpu</sub> * U * (1 + W/C);
CPU 数量可以通过如下方式获取：Runtime.getRuntime().availableProcessors();

<br>
&emsp;&emsp; 可以使用SynchronousQueue来避免任务排队，SynchronousQueue是一种在线程之间进行移交的机制，要将一个元素放入Synchronous中，
必须有另一个线程正在等待接受这个元素，如果没有线程等待并且线程池的大小小于最小值，那么ThreadPoolExecutor将创建一个新的线程，
否则根据饱和策略，这个任务将被拒绝。只有当线程池是无界的或者可以拒绝任务时，SynchronousQueue才有实际价值。newCachedThreadPool使用了它。

<br>
&emsp;&emsp; LinkedBlockingQueue或ArrayBlockingQueue这种FIFO队列，任务执行顺序与到达顺序相同，如果想进一步控制任务执行顺序，
可以使用PriorityBlockingQueue，任务顺序是根据自然顺序或者Comparator来定义的。

<br>
&emsp;&emsp; 只有当任务相互独立时，为线程池或工作队列设置界限才是合理的，如果任务之间有依赖性，那么有界的线程池会导致线程饥饿死锁问题。
此时应该使用无界的线程池，例如newCachedThreadPool。

<br>
&emsp;&emsp; 当有界队列被填满后，饱和策略开始发挥作用，ThreadPoolExecutor饱和策略可以通过调用setRejectedExecutionHandler来修改。
JDK提供了几种RejectedExecutionHandler实现：AbortPolicy、CallerRunsPolicy、DiscardPolicy、DiscardOldestPolicy。

<br>
&emsp;&emsp; 中止(Abort) 是默认的饱和策略，该策略将抛出未检查的RejectedExecutionException。调用者捕获这个异常。
当新提交的任务无法保存到队列中等待执行时，抛弃(Discard)策略会抛弃改任务，抛弃最旧的策略将会抛弃下一个即将被执行的任务，然后尝试重新提交新的任务。
如果是优先队列，那么抛弃最旧的策略将导致抛弃优先级最高的任务，因此最好不要将抛弃最旧的饱和策略和优先级队列一起使用。

<br>
&emsp;&emsp; 调用者运行(CallerRuns)策略实现了一种调节机制。既不抛弃任务，也不抛出异常。而是将任务回退到调用者，从而降低新任务的流量。
它不会在线程池中执行新提交的任务，而是在一个调用了execute的线程中执行该任务。

<br>
&emsp;&emsp; 当串行循环中的各个操作之间彼此独立，并且每个迭代操作执行的工作量比管理一个新任务时带来的开销更多，那么这个串行循环就适合并行化。

<h2 id="5">5.活跃性、性能与测试</h2>
&emsp;&emsp; 如果在A线程持有锁L并想获得锁M的同时，B线程持有锁M并想获得锁L，那么A、B两个线程将会永远等待下去，这就是最简单的死锁。

<br>
&emsp;&emsp; 如果两个线程试图以不同的顺序来获得相同的锁，那么可能发生锁顺序死锁，如果所有线程以固定的顺序获得锁，那么在程序中不会出现锁顺序死锁。
    
    <p>
       A -> 锁住left -> 尝试锁住right -> 永久等待
       B -------> 锁住right -> 尝试锁住left -> 永久等待
    </p>
   
<br>
&emsp;&emsp; 如果在持有锁时调用某个外部方法，那么将出现活跃性问题，在这个外部方法中可能会获取其他锁(这可能会产生死锁)，或者阻塞时间过长，
导致其他线程无法及时获得当前被持有的锁。

<br>
&emsp;&emsp; 如果在调用某个方法时不需要持有锁，那么这种调用被称为开放调用。在程序中应该尽量使用开放调用，与那些在持有锁时调用外部方法的程序相比，
更易于对依赖于开放调用的程序进行死锁分析。

<h2 id="6">6.性能与可伸缩性</h2>
&emsp;&emsp; 线程最主要的目的就是提高程序的运行性能，线程可以使程序充分发挥系统的可用处理能力，从而提高系统的资源利用率。
线程还可以使程序在运行现有程序的情况下立即开始处理新的任务，从而提高系统的响应性。使用多个线程会引入额外的性能开销：线程之间的协调(如加锁、
触发信号、内存同步等)，增加的上下文切换、线程的创建和销毁、线程的调度等。如果过度的使用线程，这些开销甚至会超过由于提高吞吐量、响应性或者计算能力
所带来的性能提升。

<br>
&emsp;&emsp; 要想通过并发获得更好的性能，需要做好两件事情：更有效的利用现有处理资源，以及在出现新的处理资源时使程序尽可能利用这些新资源。

<br>

### Amdahl定律
&emsp;&emsp; Amdahl定律：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件与串行组件所占的比重。
假设F是必须被串行执行的部分，那么根据Amdahl定律，在包含N个处理器的机器中，最高的加速比为：

    <p>
        Speedup <= 1 / (F + (1 - F) / N)
    </p>

<br>
&emsp;&emsp; 当N趋近于无穷大的时候，最大的加速比趋近于 1 / F 。如果在程序中有10%的计算需要串行执行，那么最高的加速比将接近10。
在拥有10个处理器的系统中，如果程序有10%部分需要串行执行，那么最高的加速比为5.3，在拥有100个处理器的系统中，加速比可以达到9.2，
即使拥有无限多的CPU，加速比也不可能为10。

<br>

### 上下文切换
&emsp;&emsp; 如果主线程是唯一的线程，那么基本不会被调度出去。如果可运行的线程数大于CPU的数量，那么操作系统将会将某个正在运行的线程调度出来，
从而使其他线程能够使用CPU。这将导致一次上下文切换。

<br>
&emsp;&emsp; 切换上下文需要一定的开销，而在线程调度过程中需要访问由操作系统和JVM共享的数据结构。应用程序、操作系统以及JVM都使用一组相同的CPU。
在JVM和操作系统的代码中消耗越多的CPU时钟周期，应用程序的可用CPU时钟周期就越少。上下文切换的开销并不只是包含JVM和操作系统的开销。
当一个新的线程被切换进来时，它所需要的数据可能不在当前处理器的本地缓存中，因此上下文切换将导致一些缓存缺失，因而线程在首次调度运行时会更加缓慢。
这就是为什么调度器会为每个可运行的线程分配一个最小执行时间，即使有其他的线程正在等待执行：它将上下文切换的开销分摊到更多不会中断的执行时间上，
从而提高整体的吞吐量。

<br>
&emsp;&emsp; 当线程由于等待某个发生竞争的锁而被阻塞时，JVM会将这个线程挂起，并允许它被交换出去。在程序中发生越多的阻塞，与CPU密集型的程序，
就会发生越多的上下文切换，从而增加调度开销，并因此而降低吞吐量。无阻塞算法有助于减小上下文切换。上下文切换的开销相当于5000-10000个时钟周期，
也就是几微秒。UNIX系统的vmstat命令和Windows系统的perfmon工具都能报告上下文切换次数以及在内核中执行时间所占比例等信息。
如果内核占用率较高（超过10%），那么通常表示调度活动发生的很频繁，这很可能是由I／O或竞争锁导致的阻塞引起的。

<br>

### 内存同步
&emsp;&emsp; 同步操作的性能开销包括多个方面。在synchronized和volatile提供的可见性保证中可能使用一些特殊指令，即内训栅栏。
内存栅栏可以刷新缓存使缓存无效，刷新硬件的写缓冲，以及停止执行管道。内存栅栏可能同样会对性能带来间接的影响。因为它们将抑制一些编译器优化操作。
在内存栅栏中，大多数操作是不能被重排序的。

<br>
&emsp;&emsp; synchronized机制针对无竞争的同步做了优化，volatile通常是非竞争的。一个快速通道（Fast-Path）的非竞争同步将消耗20-250个时钟周期。
虽然无竞争同步的开销不为0，但是对于程序整体的影响微乎其微。现代的JVM会通过优化来去掉一些不会发生竞争的锁，从而减少不必要的同步开销。
如果一个锁对象只能由当前线程访问，那么JVM就可以通过优化来去掉这个锁获取操作。

<br>
&emsp;&emsp; 一些JVM能通过逸出分析找到不会发布到堆的本地对象引用（这个引用是线程本地的）。getStoogeNames会将Vector上锁获取释放四次。
但是一个智能的运行时编译器会分析调用，从而使stooges及其内部状态不会逸出，因此可以去掉这4次对锁获取操作。

    <p>
        public String getStoogeNames() {
            List<String> stooges = new Vector<String>();
            stooges.add("Moe");
            stooges.add("Larry");
            stooges.add("Curly");
            return stooges.toString();
         }
    </p>




